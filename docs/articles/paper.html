<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Understanding mixed effects models through data simulation • lmem.sim</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="Understanding mixed effects models through data simulation">
<meta property="og:description" content="lmem.sim">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">lmem.sim</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">0.0.0.9000</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fas fa fas fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/paper.html">Understanding mixed effects models through data simulation</a>
    </li>
    <li>
      <a href="../articles/appendix1a_example_code.html">Appendix 1a: Example Code</a>
    </li>
    <li>
      <a href="../articles/appendix1b_example_code.html">Appendix 1b: Example Code (no tidyverse)</a>
    </li>
    <li>
      <a href="../articles/appendix1c_sensitivity.html">Appendix 1c: Sensitivity Analysis</a>
    </li>
    <li>
      <a href="../articles/appendix2_extended_example.html">Appendix 2: Extended Examples</a>
    </li>
    <li>
      <a href="../articles/appendix3a_binomial.html">Appendix 3a: Binomial Example</a>
    </li>
    <li>
      <a href="../articles/appendix3b_extended_binomial.html">Appendix 3b: Extended Binomial Example</a>
    </li>
  </ul>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right"></ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><script src="paper_files/accessible-code-block-0.0.1/empty-anchor.js"></script><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>Understanding mixed effects models through data simulation</h1>
                        <h4 class="author">Lisa M. DeBruine</h4>
            <address class="author_afil">
      1<br><a class="author_email" href="mailto:#"></a><a href="mailto:lisa.debruine@glasgow.ac.uk" class="email">lisa.debruine@glasgow.ac.uk</a>
      </address>
                              <h4 class="author">Dale J. Barr</h4>
            <address class="author_afil">
      1<br><a class="author_email" href="mailto:#"></a><a href="mailto:dale.barr@glasgow.ac.uk" class="email">dale.barr@glasgow.ac.uk</a>
      </address>
                  
      
      
      <div class="hidden name"><code>paper.Rmd</code></div>

    </div>

    
        <div class="abstract">
      <p class="abstract">Abstract</p>
      <p>Experimental designs that sample both subjects and stimuli from a larger population need to account for random effects of both subjects and stimuli using mixed effects models. However, much of this research is analyzed using ANOVA on aggregated responses because researchers are not confident specifying and interpreting mixed effects models. The tutorial will explain how to simulate data with random effects structure and analyse the data using linear mixed effects regression (with the lme4 R package), with a focus on interpreting the output in light of the simulated parameters. Data simulation can not only enhance understanding of how these models work, but also enables researchers to perform power calculations for complex designs. All materials associated with this article can be accessed at <a href="https://osf.io/3cz2e/" class="uri">https://osf.io/3cz2e/</a>.</p>
    </div>
    
<div id="background" class="section level1">
<h1 class="hasAnchor">
<a href="#background" class="anchor"></a>Background</h1>
<p>In this article, we walk through the simulation and analysis of multilevel data with crossed random effects of subjects and stimuli. The article’s target audience is researchers who work with experimental designs that sample subjects and stimuli, such as is the case for a large amount of experimental research in face perception, psycholinguistics, and social cognition. Simulation is useful not only for helping understand how models work, but also for estimating power when planning a study or performing a sensitivity analysis. The tutorial assumes basic familiarity with R programming.</p>
</div>
<div id="generalizing-to-a-population-of-encounters" class="section level1">
<h1 class="hasAnchor">
<a href="#generalizing-to-a-population-of-encounters" class="anchor"></a>Generalizing to a population of encounters</h1>
<p>Many research questions in psychology and neuroscience are questions about certain types of <em>events</em>: What happens when people encounter particular types of stimuli? For example: Do people recognize abstract words faster than concrete words? What impressions do people form about a target person’s personality based on their vocal qualities? Can people categorize emotional expressions more quickly on the faces of social ingroup members than on the faces of outgroup members? How do brains respond to threatening versus non-threatening stimuli? In all of these situations, researchers would like to be able to make general statements about phenomena that go beyond the particular participants and particular stimuli that they happen to have chosen for the specific study. Traditionally, people speak of such designs as having <em>crossed random factors</em> of participants and stimuli, and think of the goal of inference as being simultaneous generalization to both populations. However, it may be more intuitive to construe the goal as generalizing to a single population of <em>events</em> called <em>encounters</em>: we want to say something general about what happens when our two types of sampling units meet—when a typical subject encounters (and responds to) a typical stimulus <span class="citation">(Barr 2018)</span>.</p>
<p>Most analyses using conventional statistical techniques, such as analysis of variance and t-test, commit the fallacy of treating stimuli as fixed rather than random. For example, imagine a sample of participants are rating the trustworthiness of a sample of faces, with the goal being to determine whether the faces of people born on even numbered days look more trustworthy than those born on odd-numbered days. Obviously, they don’t. At the extreme, imagine we only sample a single face from each category, but have 100 people rate each face. If our analysis treats the sample of faces as <em>fixed</em>, or a perfect representation of the larger population of faces on Earth, we will be almost guaranteed a significant difference in one direction or the other. We will have sufficient power to detect even tiny differences in apparent trustworthiness, so this result will be highly replicable with large samples of raters. As you increase the number of faces in the sample, the problem gets better (the sample means are more likely to approximate the population means), but if you increase the number of raters (and thus power to detect small differences in the sample means), it gets worse again.</p>
<p>The problem, and the solutions to the problem, have been known in psycholinguistics for over 50 years <span class="citation">(Coleman 1964; Clark 1973)</span>, and most psycholinguistic journals require authors to demonstrate generalizability of findings over stimuli as well as over subjects. Even so, the quasi-<span class="math inline">\(F\)</span> statistics for ANOVA (<span class="math inline">\(F'\)</span> and min-<span class="math inline">\(F'\)</span>) that Clark proposed as a solution were widely recognized as unreasonably conservative <span class="citation">(Forster and Dickinson 1976)</span>, and until fairly recently, most psycholinguists performed separate by-subjects (<span class="math inline">\(F_1\)</span>) and by-items analyses (<span class="math inline">\(F_2\)</span>), declaring an effect “significant” only if it was significant for both analyses. This <span class="math inline">\(F_1 \times F_2\)</span> approach has been widely used, despite the fact that Clark had already shown it to be invalid, since both <span class="math inline">\(F\)</span> statistics have higher than nominal false positives in the presence of a null effect—<span class="math inline">\(F_1\)</span> due to unmodeled stimulus variance, and <span class="math inline">\(F_2\)</span> due to unmodeled subject variance.</p>
<p>Recently, psycholinguists have adopted linear mixed-effects modeling as the standard for statistical analysis, given numerous advantages over ANOVA, including the ability to simultaneously model subject and stimulus variation, to gracefully deal with missing data or unbalanced designs, and to accommodate arbitrary types of continuous and categorical predictors or response variables <span class="citation">(Baayen, Davidson, and Bates 2008; Locker, Hoffman, and Bovaird 2007)</span>. This development has been facilitated by the <code>lme4</code> package for R <span class="citation">(Bates et al. 2015)</span>, which provides powerful functionality for model specification and estimation. With an appropriately specified model, mixed-effects models yield major improvements in power over quasi-<span class="math inline">\(F\)</span> approaches and avoid the increased false positive rate associated with separate <span class="math inline">\(F_1\)</span> and <span class="math inline">\(F_2\)</span> <span class="citation">(Barr et al. 2013)</span>.</p>
<p>Despite mixed-effects modeling becoming the <em>de facto</em> standard for analysis in psycholinguistics, the approach has yet to take hold in other areas where stimuli are routinely sampled, even in spite of repeated calls for improved analyses in social psychology <span class="citation">(Judd, Westfall, and Kenny 2012)</span> and neuroimaging <span class="citation">(Bedny, Aguirre, and Thompson-Schill 2007; Westfall, Nichols, and Yarkoni 2016)</span>. One of the likely reasons for the limited uptake outside of psycholinguistics is because mixed-effects models expose the analyst to a level of statistical and technical complexity far beyond most researchers’ training. While some of this complexity is specific to mixed-effects modeling, some of it is simply hidden away from users of traditional techniques by GUIs and function defaults. The novice mixed modeler is suddenly confronted with the need to make decisions about how to specify categorical predictors, which random effects to include or exclude, which of the statistics in the voluminous output to attend to, and whether and how to re-configure the optimizer function when a convergence error or singularity warning appears.</p>
<p>We are optimistic that the increasing adoption of the mixed-effects approach will improve the generalizability and thus reproducibility of studies in psychology and related fields. Models that account for subjects and stimuli (or other factors) as non-essential, exchangeable features of an experiment will better characterize the uncertainty in the resulting estimates and thus, improve the generality of inferences we draw from them <span class="citation">(Yarkoni 2019)</span>. That said, we empathize with the frustration — and sometimes, exasperation — expressed by many novices when they attempt to grapple with these models in their research. A profitable way to build understanding and confidence is through data simulation. If you can create datasets by sampling from a population where you know the ground truth about the population parameters you are interested in (e.g., means and standard deviations of each group), you can check how often and under what circumstances a statistical model will give you the correct answer. Knowing the ground truth also allows you to experiment with various modeling choices and observe their impact on a model’s performance.</p>

</div>
<div id="data-materials-and-online-resources" class="section level1">
<h1 class="hasAnchor">
<a href="#data-materials-and-online-resources" class="anchor"></a>Data, materials, and online resources</h1>
<p>The code to reproduce the analyses reported in this article and appendices with extended examples are publicly available via the Open Science Framework and can be accessed at <a href="https://osf.io/3cz2e" class="uri">https://osf.io/3cz2e</a>. This code is supplemented by web apps that perform data simulation without requiring knowledge of R code. These apps allow you to change parameters and inspect the results of LMEM and ANOVA analyses, as well as calculate power and false positive rates for these analyses.</p>
</div>
<div id="simulating-data-with-crossed-random-factors" class="section level1">
<h1 class="hasAnchor">
<a href="#simulating-data-with-crossed-random-factors" class="anchor"></a>Simulating data with crossed random factors</h1>
<p>Data simulation can play a powerful role in statistics education, enhancing understanding of the use and interpretation of statistical models and the assumptions behind them. The data simulation approach to learning about statistical models differs from the standard approach in most statistics textbooks, where the learner is presented with a step-by-step analysis of a sample of data from some population of interest. Such exercises usually culminate in inferences about characteristics of the population of interest from model estimates. Although this reflects the typical uncertain situation of the analyst, the learner cannot fully appreciate the performance of the model without knowing the ground truth. In a data simulation approach, the learner starts out knowing the ground truth about the population and writes code to simulate the process of taking and analyzing samples from that population. Giving learners knowledge of the underlying population parameters as well as the ability to explore how population parameters are reflected in model estimates can yield powerful insight into the appropriate specification of models and the interpretation of statistical output.</p>
<p>Data simulation also has a wide variety of scientific uses, one of which is to estimate properties of statistical models in situations where algorithms for computing those properties are unknown or can only be applied with difficulty. For instance, <span class="citation">Forster and Dickinson (1976)</span> used Monte Carlo simulation to explore the behavior of the quasi-<span class="math inline">\(F\)</span> statistics for ANOVA (<span class="math inline">\(F'\)</span> and min-<span class="math inline">\(F'\)</span>) under various conditions. In a Monte Carlo simulation, the long run properties of a process are estimated by generating and analyzing many simulated datasets—usually, thousands or tens of thousands of them.</p>
<p>One of the most important applications of Monte Carlo simulation is in the estimation of power for complex models. The notion of power appears most frequently in the context of study planning, where a power analysis is used to determine the target <span class="math inline">\(N\)</span> for a study. Power is the probability that a specified statistical test will generate a significant result for a sample of data of a specified size taken from a population with a specified effect. If you can characterize the population parameters, you can repeatedly simulate and analyze data from this population. The proportion of times that this procedure produces a significant result provides an estimate of the power of your test given your assumed sample size and effect size. You can adjust any parameters in this simulation in order to estimate other parameters. Instead of estimating power, you can perform a <em>sensitivity analysis</em> by varying the effect size while holding the sample size and desired power constant—for instance, to determine the minimum effect size that your analysis can detect with 80% power and an <span class="math inline">\(N\)</span> of 200 per group. You can also set the population effect size to zero and calculate the proportion of significant results to check if your analysis procedure inflates <em>false positives</em>.</p>
<p>For most traditional statistical procedures such as <span class="math inline">\(t\)</span>-test or ANOVA, there are analytical procedures for estimating power. <span class="citation">Westfall, Kenny, and Judd (2014)</span> present analytic power curves for simple mixed effects designs such as the one described in this tutorial (with a corresponding app at <a href="https://jakewestfall.shinyapps.io/crossedpower" class="uri">https://jakewestfall.shinyapps.io/crossedpower</a>). But even where analytical solutions exist, simulation can still be useful to estimate power or false positive rates, because real psychological data nearly always deviates from the statistical assumptions behind traditional procedures. For instance, most statistical procedures used in psychology assume a continuous and unbounded dependent variable, but it is often the case that researchers use discrete (e.g., Likert) response scales. When assumptions are not met, power simulations can provide a more reliable estimate than analytical procedures.</p>
<p>To give an overview of the simulation task, we will simulate data from a design with crossed random factors of subjects and stimuli, fit a model to the simulated data, and then see whether the resulting sample estimates are similar to the population values we specified when simulating the data. In this hypothetical study, subjects classify the emotional expressions of faces as quickly as possible, and we use their response time as the primary dependent variable. Let’s imagine that the faces are of two types: either from the subject’s ingroup or from an outgroup. For simplicity, we further assume that each face appears only once in the stimulus set. The key question is whether there is any difference in classification speed across the type of face.</p>
<div id="required-software" class="section level2">
<h2 class="hasAnchor">
<a href="#required-software" class="anchor"></a>Required software</h2>
<p>The simulation will be presented in the R programming language <span class="citation">(R Core Team 2018)</span>. To run the code, you will need to have some add-on packages available.</p>
<div class="sourceCode" id="cb1"><pre class="downlit">
<span class="co"># load required packages</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="st"><a href="https://github.com/lme4/lme4/">"lme4"</a></span><span class="op">)</span>        <span class="co"># model specification / estimation</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="st"><a href="https://github.com/runehaubo/lmerTestR">"lmerTest"</a></span><span class="op">)</span>    <span class="co"># provides p-values in the output</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="st"><a href="http://tidyverse.tidyverse.org">"tidyverse"</a></span><span class="op">)</span>   <span class="co"># data wrangling and visualisation</span></pre></div>
<p>Because the code uses random number generation, if you want to reproduce the exact results below you will need to set the random number seed at the top of your script and ensure you are using R version 3.6.0 or higher. If you change the seed or are using a lower version of R, your exact numbers will differ, but the procedure will still produce a valid simulation.</p>
<div class="sourceCode" id="cb2"><pre class="downlit">
<span class="co"># ensure this script returns the same results on each run</span>
<span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">8675309</span><span class="op">)</span></pre></div>
</div>
<div id="establishing-the-data-generating-parameters" class="section level2">
<h2 class="hasAnchor">
<a href="#establishing-the-data-generating-parameters" class="anchor"></a>Establishing the data-generating parameters</h2>
<p>The first thing to do is to set up the parameters that govern the process we assume to give rise to the data, the <em>data-generating process</em> or DGP. Let’s start by defining the sample size: In this hypothetical study, each of 100 subjects will respond to all 50 stimulus items (25 ingroup and 25 outgroup), for a total of 5000 observations.</p>
<div id="specify-the-data-structure" class="section level3">
<h3 class="hasAnchor">
<a href="#specify-the-data-structure" class="anchor"></a>Specify the data structure</h3>
<p> </p>
<p>We want the resulting data to be in long format, with the structure shown in Table @ref(tab:data-example), where each row is a single observation for each trial. The variable <code>subj_id</code> runs from <code>1</code> to <code>100</code> and indexes the subject number; <code>item_id</code> runs from <code>1</code> to <code>50</code> and indexes the item number; <code>category</code> is whether the face is ingroup or outgroup, with items 1-25 always ingroup and items 26-50 always outgroup; and <code>RT</code> is the participant’s response time for that trial. Note that a trial is uniquely identified by the combination of the <code>subj_id</code> and <code>item_id</code> labels.</p>
<caption>
(#tab:data-example)
</caption>
<div custom-style="Table Caption">
<em>The target data structure.</em>
</div>
<table class="table">
<thead><tr class="header">
<th align="right">row</th>
<th align="left">subj_id</th>
<th align="left">item_id</th>
<th align="left">category</th>
<th align="right">RT</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="right">1</td>
<td align="left">1</td>
<td align="left">1</td>
<td align="left">ingroup</td>
<td align="right">750.2</td>
</tr>
<tr class="even">
<td align="right">2</td>
<td align="left">1</td>
<td align="left">2</td>
<td align="left">ingroup</td>
<td align="right">836.1</td>
</tr>
<tr class="odd">
<td align="right">…</td>
<td align="left">…</td>
<td align="left">…</td>
<td align="left">…</td>
<td align="right">…</td>
</tr>
<tr class="even">
<td align="right">49</td>
<td align="left">1</td>
<td align="left">49</td>
<td align="left">outgroup</td>
<td align="right">811.9</td>
</tr>
<tr class="odd">
<td align="right">50</td>
<td align="left">1</td>
<td align="left">50</td>
<td align="left">outgroup</td>
<td align="right">801.8</td>
</tr>
<tr class="even">
<td align="right">51</td>
<td align="left">2</td>
<td align="left">1</td>
<td align="left">ingroup</td>
<td align="right">806.7</td>
</tr>
<tr class="odd">
<td align="right">52</td>
<td align="left">2</td>
<td align="left">2</td>
<td align="left">ingroup</td>
<td align="right">805.9</td>
</tr>
<tr class="even">
<td align="right">…</td>
<td align="left">…</td>
<td align="left">…</td>
<td align="left">…</td>
<td align="right">…</td>
</tr>
<tr class="odd">
<td align="right">5000</td>
<td align="left">100</td>
<td align="left">50</td>
<td align="left">outgroup</td>
<td align="right">859.9</td>
</tr>
</tbody>
</table>
<p>Note that for independent variables in designs where subjects and stimuli are crossed, you can’t think of factors as being solely “within” or “between” because we have two sampling units; you must ask not only whether independent variables are within- or between- subjects, but also whether they are within- or between- stimulus items. Recall that a within-subjects factor is one where each and every subject receives all of the levels, and a between-subjects factors is one where each subject receives only one of the levels. Likewise, a within-items factor is one for which each stimulus receives all of the levels. For our current example, the ingroup/outgroup factor (<code>category</code>) is within subjects but between items, given that each stimulus item is either ingroup or outgroup.</p>
</div>
<div id="specify-the-fixed-effect-parameters" class="section level3">
<h3 class="hasAnchor">
<a href="#specify-the-fixed-effect-parameters" class="anchor"></a>Specify the fixed effect parameters</h3>
<caption>
(#tab:paramdef)
</caption>
<div custom-style="Table Caption">
<em>Variables in the data-generating model and associated R code.</em>
</div>
<table class="table">
<thead><tr class="header">
<th align="left">model</th>
<th align="left">code</th>
<th align="left">description</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left"><span class="math inline">\(RT_{si}\)</span></td>
<td align="left"></td>
<td align="left">reaction time for subject <span class="math inline">\(s\)</span> to item <span class="math inline">\(i\)</span>
</td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(X_i\)</span></td>
<td align="left"></td>
<td align="left">condition for item <span class="math inline">\(i\)</span> (-.5 = ingroup, .5 = outgroup)</td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(\beta_0\)</span></td>
<td align="left"></td>
<td align="left">intercept; grand mean RT</td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(\beta_1\)</span></td>
<td align="left"></td>
<td align="left">slope; mean effect of ingroup/outgroup</td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(\tau_0\)</span></td>
<td align="left"></td>
<td align="left">standard deviation of by-subject random intercepts</td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(\tau_1\)</span></td>
<td align="left"></td>
<td align="left">standard deviation of by-subject random slopes</td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(\rho\)</span></td>
<td align="left"></td>
<td align="left">correlation between by-subject random intercepts and slopes</td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(\omega_0\)</span></td>
<td align="left"></td>
<td align="left">standard deviation of by-item random intercepts</td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(\sigma\)</span></td>
<td align="left"></td>
<td align="left">standard deviation of residuals</td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(T_{0s}\)</span></td>
<td align="left"></td>
<td align="left">random intercept for subject <span class="math inline">\(s\)</span>
</td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(T_{1s}\)</span></td>
<td align="left"></td>
<td align="left">random slope for subject <span class="math inline">\(s\)</span>
</td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(O_{0i}\)</span></td>
<td align="left"></td>
<td align="left">random intercept for item <span class="math inline">\(i\)</span>
</td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(e_{si}\)</span></td>
<td align="left"></td>
<td align="left">residual for the trial involving subject <span class="math inline">\(s\)</span> and item <span class="math inline">\(i\)</span>
</td>
</tr>
</tbody>
</table>
<p>Now that we have an appropriate structure for our simulated dataset, we need to generate the RT values. For this, we need to establish an underlying statistical model. In this and the next section, we will build up a statistical model step by step, defining variables in the code as we go along that reflect our choices for parameters. For convenience, Table @ref(tab:paramdef) lists all of the variables in the statistical model and their associated variable names in the code.</p>
<p>Let us start with a basic model and build up from there. We want a model of RT for subject <span class="math inline">\(s\)</span> and item <span class="math inline">\(i\)</span> that looks something like:</p>
<p><span class="math display">\[\begin{equation}
RT_{si} = \beta_0 + \beta_1 X_{i} + e_{si}.
\end{equation}\]</span></p>
<p>According to the formula, response <span class="math inline">\(RT_{si}\)</span> for subject <span class="math inline">\(s\)</span> and item <span class="math inline">\(i\)</span> is defined as sum of an intercept term <span class="math inline">\(\beta_0\)</span>, which in this example is the grand mean reaction time for the population of stimuli, plus <span class="math inline">\(\beta_1\)</span>, the mean RT difference between ingroup and outgroup stimuli, plus random noise <span class="math inline">\(e_{si}\)</span>. To make <span class="math inline">\(\beta_0\)</span> equal the grand mean and <span class="math inline">\(\beta_1\)</span> equal the mean outgroup minus the mean ingroup RT, we will code the item category variable <span class="math inline">\(X_{i}\)</span> as -.5 for the ingroup category and +.5 for the outgroup category.</p>
<p>In the model formula, we use Greek letters (<span class="math inline">\(\beta_0\)</span>, <span class="math inline">\(\beta_1\)</span>) to represent population parameters that are being directly estimated by the model. In contrast, Roman letters represent the remaining variables: observed variables whose values are determined by sampling (e.g., <span class="math inline">\(RT_{si}\)</span>, <span class="math inline">\(T_{0s}\)</span>, <span class="math inline">\(e_{si}\)</span>) or fixed by the experiment design (<span class="math inline">\(X_i\)</span>).</p>
<p>Although this model is incomplete, we can go ahead and choose parameters for <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>. For this example, we set a grand mean of 800 ms and a mean difference of 50 ms. You will need to use disciplinary expertise and/or pilot data to choose these parameters; by the end of this tutorial you will understand how to extract those parameters from an analysis.</p>
<div class="sourceCode" id="cb3"><pre class="downlit">
<span class="co"># set fixed effect parameters</span>
<span class="va">beta_0</span> <span class="op">&lt;-</span> <span class="fl">800</span> <span class="co"># intercept; i.e., the grand mean</span>
<span class="va">beta_1</span> <span class="op">&lt;-</span>  <span class="fl">50</span> <span class="co"># slope; i.e, effect of category</span></pre></div>
<p>The parameters <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> are <em>fixed effects</em>: they characterize the population of events in which a typical subject encounters a typical stimulus. Thus, we set the mean RT for a “typical” subject encountering a “typical” stimulus to 800 ms, and assume that responses are typically 50 ms slower for outgroup than ingroup faces.</p>
</div>
<div id="specify-the-random-effect-parameters" class="section level3">
<h3 class="hasAnchor">
<a href="#specify-the-random-effect-parameters" class="anchor"></a>Specify the random effect parameters</h3>
<p>This model is completely unrealistic, however, because it doesn’t allow for any individual differences among subjects or stimuli. Subjects are not identical in their response characteristics: some will be faster than average, and some slower. We can characterize the difference from the grand mean for each subject <span class="math inline">\(s\)</span> in terms of a <em>random effect</em> <span class="math inline">\(T_{0s}\)</span>, where the first subscript, 0, indicates that the deflection goes with the intercept term, <span class="math inline">\(\beta_0\)</span>. This <em>random intercept</em> term captures the value that must be added or subtracted to the intercept for subject <span class="math inline">\(s\)</span>, which in this case corresponds to how much slower or faster this subject is relative to the average reaction time of 800 ms. Just as it is unrealistic to expect the same intercept for every subject, it is also unrealistic to assume this for stimuli; it will be easier to categorize emotional expressions for some faces than others, and we can incorporate this assumption by including by-item random intercepts <span class="math inline">\(O_{0i}\)</span>, with the subscript 0 reminding us that it is a deflection from the <span class="math inline">\(\beta_0\)</span> term, and the <span class="math inline">\(i\)</span> indexing each of the 50 stimulus items (faces). Each face is assigned a unique <em>random intercept</em> that characterizes how much slower or faster responses to this particular face tend to be relative to the average reaction time of 800 ms. Adding these terms to our model yields:</p>
<p><span class="math display">\[\begin{equation}
RT_{si} = \beta_0 + T_{0s} + O_{0i} + \beta_1 X_i + e_{si} .
\end{equation}\]</span></p>
<p>Now, whatever values of <span class="math inline">\(T_{0s}\)</span> and <span class="math inline">\(O_{0i}\)</span> we end up with in our sampled dataset will depend on the luck of the draw, i.e., on which subjects and stimuli we happened to have sampled from their respective populations. Unlike fixed effects, we assume these values will differ across different realizations of the experiment where subjects and/or stimuli are different. In practice, we often re-use the same stimuli across many studies, but we still need to treat the stimuli as sampled if we want to be able to generalise our findings to the whole population of stimuli.</p>
<p>It is an important conceptual feature of mixed-effects models that they do not directly estimate the individual random effects (<span class="math inline">\(T_{0s}\)</span> and <span class="math inline">\(O_{0i}\)</span> values), but rather, they estimate the random effects parameters that characterize the distributions from which these effects are drawn. It is this feature that enables generalization beyond the particular subjects and stimuli in the experiment. We assume that each <span class="math inline">\(T_{0s}\)</span> comes from a normal distribution with a mean of zero and unknown standard deviation, <span class="math inline">\(\tau_0\)</span> (<code>tau_0</code> in the code). The mean of zero reflects the assumption that each random effect is a deflection from the grand mean. Similarly, for the by-item random intercepts, we assume the <span class="math inline">\(O_{0i}\)</span> values to be sampled from a normal distribution also with a mean of zero and with an unknown standard deviation, <span class="math inline">\(\omega_0\)</span> (<code>omega_0</code>). In our simulation, we will set the by-subject random intercept SD to 100, and the by-item random intercept SD to 80.</p>
<div class="sourceCode" id="cb4"><pre class="downlit">
<span class="co"># set random effect parameters</span>
<span class="va">tau_0</span>   <span class="op">&lt;-</span> <span class="fl">100</span> <span class="co"># by-subject random intercept sd</span>
<span class="va">omega_0</span> <span class="op">&lt;-</span>  <span class="fl">80</span> <span class="co"># by-item random intercept sd</span></pre></div>
<p>There is still a deficiency in our data-generating model related to <span class="math inline">\(\beta_1\)</span>, the fixed effect of category. Currently our model assumes that each and every subject is exactly 80 ms faster to categorize emotions on ingroup faces than on outgroup faces. Clearly, this assumption is totally unrealistic; some participants will be more sensitive to ingroup/outgroup differences than others. We can capture this in an analogous way to which we captured variation in the intercept, namely by including by-subject <em>random slopes</em> <span class="math inline">\(T_{1s}\)</span>.</p>
<p><span class="math display">\[\begin{equation}
RT_{si} = \beta_0 + T_{0s} + O_{0i} + \left(\beta_1 + T_{1s}\right) X_i + e_{si}
\end{equation}\]</span></p>
<p>The random slope <span class="math inline">\(T_{1s}\)</span> is an estimate of how much faster or slower subject <span class="math inline">\(s\)</span> is in categorizing ingroup/outgroup faces than the population mean effect <span class="math inline">\(\beta_1\)</span>, which we already set to 50 ms. Given how we coded the <span class="math inline">\(X_i\)</span> variable, the mean effect for subject <span class="math inline">\(s\)</span> is given by the <span class="math inline">\(\beta_1 + T_{1s}\)</span> term. So, a participant who is 90 ms faster on average to categorize ingroup than outgroup faces would have a random slope <span class="math inline">\(T_{1s}\)</span> of 40 (<span class="math inline">\(\beta_1 + T_{1s} = 50 + 40 = 90\)</span>). As we did for the random intercepts, we assume that the <span class="math inline">\(T_{1s}\)</span> effects are drawn from a normal distribution, with a mean of zero and standard deviation of <span class="math inline">\(\tau_1\)</span> (<code>tau_1</code> in the code). For this example, we assume the standard deviation is 40 ms.</p>
<p>But note that we are sampling <em>two</em> random effects for each subject <span class="math inline">\(s\)</span>, a random intercept <span class="math inline">\(T_{0s}\)</span> and a random slope <span class="math inline">\(T_{1s}\)</span>. It is possible for these values to be positively or negatively correlated, in which case we should not sample them independently. For instance, perhaps people who are faster than average overall (negative random intercept) also show a smaller than average effect of the ingroup/outgroup manipulation (negative random slope) due to allocating less attention to the task. We can capture this by allowing for a small positive correlation between the two factors, <code>rho</code>, which we assign to be 0.2.</p>
<p>Finally, we need to characterize the trial-level noise in the study (<span class="math inline">\(e_{si}\)</span>) in terms of its standard deviation. Here we simply assign this parameter value <code>sigma</code> to be twice the size of the by-subject random intercept SD.</p>
<div class="sourceCode" id="cb5"><pre class="downlit">
<span class="co"># set more random effect and error parameters</span>
<span class="va">tau_1</span>  <span class="op">&lt;-</span>  <span class="fl">40</span> <span class="co"># by-subject random slope sd</span>
<span class="va">rho</span>    <span class="op">&lt;-</span>  <span class="fl">.2</span> <span class="co"># correlation between intercept and slope</span>
<span class="va">sigma</span>  <span class="op">&lt;-</span> <span class="fl">200</span> <span class="co"># residual (error) sd</span></pre></div>
<p>To summarize, we established a reasonable statistical model underlying the data having the form:</p>
<p><span class="math display">\[\begin{equation}
RT_{si} = \beta_0 + T_{0s} + O_{0i} + \left(\beta_1 + T_{1s}\right) X_i + e_{si}
\end{equation}\]</span></p>
<p>The response time for subject <span class="math inline">\(s\)</span> on item <span class="math inline">\(i\)</span>, <span class="math inline">\(RT_{si}\)</span>, is decomposed into a population grand mean <span class="math inline">\(\beta_0\)</span>, a by-subject random intercept <span class="math inline">\(T_{0s}\)</span>, a by-item random intercept <span class="math inline">\(O_{0i}\)</span>, a fixed slope <span class="math inline">\(\beta_1\)</span>, a by-subject random slope <span class="math inline">\(T_{1s}\)</span>, and a trial-level residual <span class="math inline">\(e_{si}\)</span>. Our data-generating process is fully determined by seven population parameters, all denoted by Greek letters: <span class="math inline">\(\beta_0\)</span>, <span class="math inline">\(\beta_1\)</span>, <span class="math inline">\(\tau_0\)</span>, <span class="math inline">\(\tau_1\)</span>, <span class="math inline">\(\rho\)</span>, <span class="math inline">\(\omega_0\)</span>, and <span class="math inline">\(\sigma\)</span> (see Table @ref(tab:paramdef)). In the next section we will apply this data-generating process to simulate the sampling of subjects, items, and trials (encounters).</p>
</div>
</div>
<div id="simulating-the-sampling-process" class="section level2">
<h2 class="hasAnchor">
<a href="#simulating-the-sampling-process" class="anchor"></a>Simulating the sampling process</h2>
<p>Let’s first define parameters related to the number of observations. In this example, we will simulate data from 100 subjects responding to 25 ingroup faces and 25 outgroup faces. There are no between-subject factors, so we can set <code>n_subj</code> to 100. We set <code>n_ingroup</code> and <code>n_outgroup</code> to the number of stimulus items in each condition.</p>
<div class="sourceCode" id="cb6"><pre class="downlit">
<span class="co"># set number of subjects and items</span>
<span class="va">n_subj</span>     <span class="op">&lt;-</span> <span class="fl">100</span> <span class="co"># number of subjects</span>
<span class="va">n_ingroup</span>  <span class="op">&lt;-</span>  <span class="fl">25</span> <span class="co"># number of ingroup stimuli</span>
<span class="va">n_outgroup</span> <span class="op">&lt;-</span>  <span class="fl">25</span> <span class="co"># number of outgroup stimuli</span></pre></div>
<div id="simulate-the-sampling-of-stimulus-items" class="section level3">
<h3 class="hasAnchor">
<a href="#simulate-the-sampling-of-stimulus-items" class="anchor"></a>Simulate the sampling of stimulus items</h3>
<p>We need to create a table listing each item <span class="math inline">\(i\)</span>, which category it is in, and its random effect <span class="math inline">\(O_{0i}\)</span>.</p>
<div class="sourceCode" id="cb7"><pre class="downlit">
<span class="co"># simulate a sample of items</span>
<span class="co"># total number of items = n_ingroup + n_outgroup</span>
<span class="va">items</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>
  item_id <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq_len</a></span><span class="op">(</span><span class="va">n_ingroup</span> <span class="op">+</span> <span class="va">n_outgroup</span><span class="op">)</span>,
  category <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"ingroup"</span>, <span class="st">"outgroup"</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">n_ingroup</span>, <span class="va">n_outgroup</span><span class="op">)</span><span class="op">)</span>,
  O_0i <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span>n <span class="op">=</span> <span class="va">n_ingroup</span> <span class="op">+</span> <span class="va">n_outgroup</span>, mean <span class="op">=</span> <span class="fl">0</span>, sd <span class="op">=</span> <span class="va">omega_0</span><span class="op">)</span>
<span class="op">)</span></pre></div>
<p>For the first variable in the dataset, <code>item_id</code>, we have used <code><a href="https://rdrr.io/r/base/seq.html">seq_len()</a></code> to assign a unique integer to each of the 50 stimulus faces; these IDs function like names. The <code>category</code> variable designates whether the face is ingroup or outgroup, with the first 25 items being ingroup and the last 25 being outgroup. Finally, we sample the values of <span class="math inline">\(O_{0i}\)</span> from a normal distribution using the <code><a href="https://rdrr.io/r/stats/Normal.html">rnorm()</a></code> function, with a mean of 0 and SD of <span class="math inline">\(\omega_0\)</span>.</p>
<p>Let us introduce a numeric predictor to represent what category each stimulus item <span class="math inline">\(i\)</span> appears in (i.e., for the <span class="math inline">\(X_i\)</span> in our model). Since we predict that responses to ingroup faces will be faster than outgroup faces, we set ingroup to -0.5 and outgroup to +0.5. We will later multiply this <em>effect coded</em> factor by the fixed effect of category (<code>beta_1</code> = 50) to simulate data where the ingroup faces are on average -25 ms different from the grand mean, while the outgroup faces are on average 25 ms different from the grand mean. After adding this variable, the resulting table <code>items</code> should look like Table @ref(tab:items-table), although the specific values you obtain for <span class="math inline">\(O_{0i}\)</span> may differ, depending on whether you set the random seed.</p>
<div class="sourceCode" id="cb8"><pre class="downlit">
<span class="co"># effect-code category</span>
<span class="va">items</span><span class="op">$</span><span class="va">X_i</span> <span class="op">&lt;-</span> <span class="fu">recode</span><span class="op">(</span><span class="va">items</span><span class="op">$</span><span class="va">category</span>, <span class="st">"ingroup"</span> <span class="op">=</span> <span class="op">-</span><span class="fl">0.5</span>, <span class="st">"outgroup"</span> <span class="op">=</span> <span class="op">+</span><span class="fl">0.5</span><span class="op">)</span></pre></div>
<p>In R, most regression procedures can handle two-level factors like <code>category</code> as predictor variables. By default, the procedure will create a new numeric predictor that codes one level of the factor as zero and the other as one. Why not just use the defaults? The short explanation is that the default of 0, 1 coding is not well-suited to the kinds of factorial experimental designs often found in psychology and related fields. For the current example, using the default coding for the <span class="math inline">\(X\)</span> predictor would change the interpretation of <span class="math inline">\(\beta_0\)</span>: instead of the grand mean, it would reflect the mean for the group coded as zero. One could change the default, but we feel it is better to be explicit in the code about what values are being used. See <a href="https://talklab.psy.gla.ac.uk/tvw/catpred" class="uri">https://talklab.psy.gla.ac.uk/tvw/catpred</a> for further discussion; see also the R mixed modeling package <code>afex</code> <span class="citation">(Singmann et al. 2019)</span>, which provides better defaults for specifying categorical predictors in ANOVA-style designs.</p>
<caption>
(#tab:items-table)
</caption>
<div custom-style="Table Caption">
<em>The resulting sample of items.</em>
</div>
<table class="table">
<thead><tr class="header">
<th align="left"></th>
<th align="left"></th>
<th align="right"></th>
<th align="right"></th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">1</td>
<td align="left">ingroup</td>
<td align="right">-79.7</td>
<td align="right">-0.5</td>
</tr>
<tr class="even">
<td align="left">2</td>
<td align="left">ingroup</td>
<td align="right">57.7</td>
<td align="right">-0.5</td>
</tr>
<tr class="odd">
<td align="left">3</td>
<td align="left">ingroup</td>
<td align="right">-49.4</td>
<td align="right">-0.5</td>
</tr>
<tr class="even">
<td align="left">4</td>
<td align="left">ingroup</td>
<td align="right">162.4</td>
<td align="right">-0.5</td>
</tr>
<tr class="odd">
<td align="left">5</td>
<td align="left">ingroup</td>
<td align="right">85.2</td>
<td align="right">-0.5</td>
</tr>
<tr class="even">
<td align="left">6</td>
<td align="left">ingroup</td>
<td align="right">79</td>
<td align="right">-0.5</td>
</tr>
<tr class="odd">
<td align="left">…</td>
<td align="left">…</td>
<td align="right">…</td>
<td align="right">…</td>
</tr>
<tr class="even">
<td align="left">44</td>
<td align="left">outgroup</td>
<td align="right">54.7</td>
<td align="right">0.5</td>
</tr>
<tr class="odd">
<td align="left">45</td>
<td align="left">outgroup</td>
<td align="right">-20.2</td>
<td align="right">0.5</td>
</tr>
<tr class="even">
<td align="left">46</td>
<td align="left">outgroup</td>
<td align="right">-12.1</td>
<td align="right">0.5</td>
</tr>
<tr class="odd">
<td align="left">47</td>
<td align="left">outgroup</td>
<td align="right">-70</td>
<td align="right">0.5</td>
</tr>
<tr class="even">
<td align="left">48</td>
<td align="left">outgroup</td>
<td align="right">-158.2</td>
<td align="right">0.5</td>
</tr>
<tr class="odd">
<td align="left">49</td>
<td align="left">outgroup</td>
<td align="right">19</td>
<td align="right">0.5</td>
</tr>
<tr class="even">
<td align="left">50</td>
<td align="left">outgroup</td>
<td align="right">2.9</td>
<td align="right">0.5</td>
</tr>
</tbody>
</table>
</div>
<div id="simulate-the-sampling-of-subjects" class="section level3">
<h3 class="hasAnchor">
<a href="#simulate-the-sampling-of-subjects" class="anchor"></a>Simulate the sampling of subjects</h3>
<p>Now we will simulate the sampling of individual subjects, resulting in a table listing each subject and their two correlated random effects. This will be slightly more complicated that what we just did, because we cannot simply sample the <span class="math inline">\(T_{0s}\)</span> values from a univariate distribution using <code><a href="https://rdrr.io/r/stats/Normal.html">rnorm()</a></code> independently from the <span class="math inline">\(T_{1s}\)</span> values. Instead, we must sample <span class="math inline">\(\left&lt;T_{0s}, T_{1s}\right&gt;\)</span> <em>pairs</em>—one pair for each subject—from a bivariate normal distribution. To do this, we will use the <code>mvrnorm()</code> function, a multivariate version of <code><a href="https://rdrr.io/r/stats/Normal.html">rnorm()</a></code> from the MASS package that comes pre-installed with R. We specify the three parameters describing this distribution—two variances and a correlation—by entering them into a 2x2 <em>variance-covariance</em> matrix using the <code><a href="https://rdrr.io/r/base/matrix.html">matrix()</a></code> function, and then passing this matrix to <code>mvrnorm()</code> using the <code>Sigma</code> argument. This requires converting the standard deviations into variances (by squaring them) and calculating the covariance, which is the product of the correlation and two standard deviations, i.e., <span class="math inline">\(\rho \times \tau_0 \times \tau_1\)</span>.</p>
<p>We only need this one function from MASS, so we can call it directly using the <code>package::function()</code> syntax instead of loading the library (specifically, <code><a href="https://rdrr.io/pkg/MASS/man/mvrnorm.html">MASS::mvrnorm()</a></code> instead of <code><a href="http://www.stats.ox.ac.uk/pub/MASS4/">library(MASS)</a></code>). The resulting table <code>subjects</code> should have the structure shown in Table @ref(tab:subj-table).</p>
<div class="sourceCode" id="cb9"><pre class="downlit">
<span class="co"># simulate a sample of subjects</span>

<span class="co"># calculate random intercept / random slope covariance</span>
<span class="va">covar</span> <span class="op">&lt;-</span> <span class="va">rho</span> <span class="op">*</span> <span class="va">tau_0</span> <span class="op">*</span> <span class="va">tau_1</span>

<span class="co"># put values into variance-covariance matrix</span>
<span class="va">cov_mx</span>  <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span>
  <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">tau_0</span><span class="op">^</span><span class="fl">2</span>, <span class="va">covar</span>,
    <span class="va">covar</span>,   <span class="va">tau_1</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span>,
  nrow <span class="op">=</span> <span class="fl">2</span>, byrow <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>

<span class="co"># generate the by-subject random effects</span>
<span class="va">subject_rfx</span> <span class="op">&lt;-</span> <span class="fu">MASS</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/MASS/man/mvrnorm.html">mvrnorm</a></span><span class="op">(</span>n <span class="op">=</span> <span class="va">n_subj</span>,
                             mu <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span>T_0s <span class="op">=</span> <span class="fl">0</span>, T_1s <span class="op">=</span> <span class="fl">0</span><span class="op">)</span>,
                             Sigma <span class="op">=</span> <span class="va">cov_mx</span><span class="op">)</span>

<span class="co"># combine with subject IDs</span>
<span class="va">subjects</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>subj_id <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq_len</a></span><span class="op">(</span><span class="va">n_subj</span><span class="op">)</span>,
                       <span class="va">subject_rfx</span><span class="op">)</span></pre></div>
<caption>
(#tab:subj-table)
</caption>
<div custom-style="Table Caption">
<em>The resulting sample of subjects.</em>
</div>
<table class="table">
<thead><tr class="header">
<th align="left"></th>
<th align="right"></th>
<th align="right"></th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">1</td>
<td align="right">-14.7</td>
<td align="right">11.1</td>
</tr>
<tr class="even">
<td align="left">2</td>
<td align="right">-8.4</td>
<td align="right">-36.7</td>
</tr>
<tr class="odd">
<td align="left">3</td>
<td align="right">87.7</td>
<td align="right">-47.5</td>
</tr>
<tr class="even">
<td align="left">4</td>
<td align="right">209.3</td>
<td align="right">62.9</td>
</tr>
<tr class="odd">
<td align="left">5</td>
<td align="right">-23.6</td>
<td align="right">21.5</td>
</tr>
<tr class="even">
<td align="left">6</td>
<td align="right">90.1</td>
<td align="right">56.7</td>
</tr>
<tr class="odd">
<td align="left">…</td>
<td align="right">…</td>
<td align="right">…</td>
</tr>
<tr class="even">
<td align="left">94</td>
<td align="right">99.5</td>
<td align="right">-31</td>
</tr>
<tr class="odd">
<td align="left">95</td>
<td align="right">44.3</td>
<td align="right">69.3</td>
</tr>
<tr class="even">
<td align="left">96</td>
<td align="right">12.2</td>
<td align="right">37.1</td>
</tr>
<tr class="odd">
<td align="left">97</td>
<td align="right">-121.9</td>
<td align="right">42.3</td>
</tr>
<tr class="even">
<td align="left">98</td>
<td align="right">-49.9</td>
<td align="right">-41.1</td>
</tr>
<tr class="odd">
<td align="left">99</td>
<td align="right">-134.5</td>
<td align="right">16.6</td>
</tr>
<tr class="even">
<td align="left">100</td>
<td align="right">-30.2</td>
<td align="right">37.5</td>
</tr>
</tbody>
</table>
<p>An alternative way to sample from a bivariate distribution would be to use the function <code>rnorm_multi()</code> from the <code>faux</code> package <span class="citation">(DeBruine 2020)</span>, which generates a table of <code>n</code> simulated values from a multivariate normal distribution by specifying the means (<code>mu</code>) and standard deviations (<code>sd</code>) of each variable, plus the correlations (<code>r</code>), which can be either a single value (applied to all pairs), a correlation matrix, or a vector of the values in the upper right triangle of the correlation matrix.</p>
<div class="sourceCode" id="cb10"><pre class="downlit">
<span class="co"># simulate a sample of subjects</span>

<span class="co"># sample from a multivariate random distribution </span>
<span class="va">subjects</span> <span class="op">&lt;-</span> <span class="fu">faux</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/faux/man/rnorm_multi.html">rnorm_multi</a></span><span class="op">(</span>
  n <span class="op">=</span> <span class="va">n_subj</span>, 
  mu <span class="op">=</span> <span class="fl">0</span>, <span class="co"># means for random effects are always 0</span>
  sd <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">tau_0</span>, <span class="va">tau_1</span><span class="op">)</span>, <span class="co"># set SDs</span>
  r <span class="op">=</span> <span class="va">rho</span>, <span class="co"># set correlation, see ?faux::rnorm_multi</span>
  varnames <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"T_0s"</span>, <span class="st">"T_1s"</span><span class="op">)</span>
<span class="op">)</span>

<span class="co"># add subject IDs</span>
<span class="va">subjects</span><span class="op">$</span><span class="va">subj_id</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq_len</a></span><span class="op">(</span><span class="va">n_subj</span><span class="op">)</span></pre></div>
</div>
<div id="simulate-trials-encounters" class="section level3">
<h3 class="hasAnchor">
<a href="#simulate-trials-encounters" class="anchor"></a>Simulate trials (encounters)</h3>
<p>Since all subjects respond to all items, we can set up a table of trials by making a table with every possible combination of the rows in the subject and item tables using the tidyverse function <code>crossing()</code>. Each trial has random error associated with it, reflecting fluctuations in trial-by-trial performance due to unknown factors; we simulate this by sampling values from a normal distribution with a mean of 0 and SD of <code>sigma</code>. The resulting table should correspond to Table @ref(tab:trials-table).</p>
<div class="sourceCode" id="cb11"><pre class="downlit">
<span class="co"># cross subject and item IDs; add an error term</span>
<span class="co"># nrow(.) is the number of rows in the table</span>
<span class="va">trials</span> <span class="op">&lt;-</span> <span class="fu">crossing</span><span class="op">(</span><span class="va">subjects</span>, <span class="va">items</span><span class="op">)</span>  <span class="op">%&gt;%</span>
  <span class="fu">mutate</span><span class="op">(</span>e_si <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">.</span><span class="op">)</span>, mean <span class="op">=</span> <span class="fl">0</span>, sd <span class="op">=</span> <span class="va">sigma</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu">select</span><span class="op">(</span><span class="va">subj_id</span>, <span class="va">item_id</span>, <span class="va">category</span>, <span class="va">X_i</span>, <span class="fu">everything</span><span class="op">(</span><span class="op">)</span><span class="op">)</span></pre></div>
<caption>
(#tab:trials-table)
</caption>
<div custom-style="Table Caption">
<em>The resulting table of trials (encounters).</em>
</div>
<table class="table">
<thead><tr class="header">
<th align="left"></th>
<th align="left"></th>
<th align="left"></th>
<th align="right"></th>
<th align="right"></th>
<th align="right"></th>
<th align="right"></th>
<th align="right"></th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">1</td>
<td align="left">1</td>
<td align="left">ingroup</td>
<td align="right">-0.50</td>
<td align="right">-14.65</td>
<td align="right">11.13</td>
<td align="right">-79.73</td>
<td align="right">-66.54</td>
</tr>
<tr class="even">
<td align="left">1</td>
<td align="left">2</td>
<td align="left">ingroup</td>
<td align="right">-0.50</td>
<td align="right">-14.65</td>
<td align="right">11.13</td>
<td align="right">57.75</td>
<td align="right">-34.74</td>
</tr>
<tr class="odd">
<td align="left">1</td>
<td align="left">3</td>
<td align="left">ingroup</td>
<td align="right">-0.50</td>
<td align="right">-14.65</td>
<td align="right">11.13</td>
<td align="right">-49.38</td>
<td align="right">-37.49</td>
</tr>
<tr class="even">
<td align="left">1</td>
<td align="left">4</td>
<td align="left">ingroup</td>
<td align="right">-0.50</td>
<td align="right">-14.65</td>
<td align="right">11.13</td>
<td align="right">162.35</td>
<td align="right">231.26</td>
</tr>
<tr class="odd">
<td align="left">1</td>
<td align="left">5</td>
<td align="left">ingroup</td>
<td align="right">-0.50</td>
<td align="right">-14.65</td>
<td align="right">11.13</td>
<td align="right">85.23</td>
<td align="right">-187.64</td>
</tr>
<tr class="even">
<td align="left">1</td>
<td align="left">6</td>
<td align="left">ingroup</td>
<td align="right">-0.50</td>
<td align="right">-14.65</td>
<td align="right">11.13</td>
<td align="right">78.98</td>
<td align="right">104.81</td>
</tr>
<tr class="odd">
<td align="left">…</td>
<td align="left">…</td>
<td align="left">…</td>
<td align="right">…</td>
<td align="right">…</td>
<td align="right">…</td>
<td align="right">…</td>
<td align="right">…</td>
</tr>
<tr class="even">
<td align="left">100</td>
<td align="left">44</td>
<td align="left">outgroup</td>
<td align="right">0.50</td>
<td align="right">-30.15</td>
<td align="right">37.52</td>
<td align="right">54.73</td>
<td align="right">-3.38</td>
</tr>
<tr class="odd">
<td align="left">100</td>
<td align="left">45</td>
<td align="left">outgroup</td>
<td align="right">0.50</td>
<td align="right">-30.15</td>
<td align="right">37.52</td>
<td align="right">-20.16</td>
<td align="right">18.47</td>
</tr>
<tr class="even">
<td align="left">100</td>
<td align="left">46</td>
<td align="left">outgroup</td>
<td align="right">0.50</td>
<td align="right">-30.15</td>
<td align="right">37.52</td>
<td align="right">-12.08</td>
<td align="right">87.92</td>
</tr>
<tr class="odd">
<td align="left">100</td>
<td align="left">47</td>
<td align="left">outgroup</td>
<td align="right">0.50</td>
<td align="right">-30.15</td>
<td align="right">37.52</td>
<td align="right">-69.99</td>
<td align="right">25.47</td>
</tr>
<tr class="even">
<td align="left">100</td>
<td align="left">48</td>
<td align="left">outgroup</td>
<td align="right">0.50</td>
<td align="right">-30.15</td>
<td align="right">37.52</td>
<td align="right">-158.15</td>
<td align="right">91.23</td>
</tr>
<tr class="odd">
<td align="left">100</td>
<td align="left">49</td>
<td align="left">outgroup</td>
<td align="right">0.50</td>
<td align="right">-30.15</td>
<td align="right">37.52</td>
<td align="right">19.01</td>
<td align="right">78.14</td>
</tr>
<tr class="even">
<td align="left">100</td>
<td align="left">50</td>
<td align="left">outgroup</td>
<td align="right">0.50</td>
<td align="right">-30.15</td>
<td align="right">37.52</td>
<td align="right">2.89</td>
<td align="right">-34.31</td>
</tr>
</tbody>
</table>
</div>
<div id="calculate-the-response-values" class="section level3">
<h3 class="hasAnchor">
<a href="#calculate-the-response-values" class="anchor"></a>Calculate the response values</h3>
<p>With this resulting table, in combination with the constants <code>beta_0</code> and <code>beta_1</code>, we have the full set of values that we need to compute the response variable <code>RT</code> according to the linear model we defined above:</p>
<p><span class="math display">\[\begin{equation}
RT_{si} = \beta_0 + T_{0s} + O_{0i} + \left(\beta_1 + T_{1s}\right) X_i + e_{si}
\end{equation}\]</span></p>
<p>Thus, we calculate the response variable <code>RT</code> by adding together:</p>
<ul>
<li>the grand intercept (<code>beta_0</code>),</li>
<li>each subject-specific random intercept (<code>T_0s</code>),</li>
<li>each item-specific random intercept (<code>O_0i</code>),</li>
<li>each sum of the category effect (<code>beta_1</code>) and the random slope (<code>T_1s</code>), multiplied by the numeric predictor (<code>X_i</code>), and</li>
<li>each residual error (<code>e_si</code>).</li>
</ul>
<p>After this we will use <code><a href="https://dplyr.tidyverse.org/reference/select.html">dplyr::select()</a></code> to keep the columns we need. Note that the resulting table (Table @ref(tab:dat-sim-table)) has the structure that we set as our goal at the start of this exercise, with the additional column <code>X_i</code>, which we will keep to use in the estimation process, described in the next section.</p>
<div class="sourceCode" id="cb12"><pre class="downlit">
<span class="co"># calculate the response variable</span>
<span class="va">dat_sim</span> <span class="op">&lt;-</span> <span class="va">trials</span> <span class="op">%&gt;%</span>
  <span class="fu">mutate</span><span class="op">(</span>RT <span class="op">=</span> <span class="va">beta_0</span> <span class="op">+</span> <span class="va">T_0s</span> <span class="op">+</span> <span class="va">O_0i</span> <span class="op">+</span> <span class="op">(</span><span class="va">beta_1</span> <span class="op">+</span> <span class="va">T_1s</span><span class="op">)</span> <span class="op">*</span> <span class="va">X_i</span> <span class="op">+</span> <span class="va">e_si</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu">select</span><span class="op">(</span><span class="va">subj_id</span>, <span class="va">item_id</span>, <span class="va">category</span>, <span class="va">X_i</span>, <span class="va">RT</span><span class="op">)</span></pre></div>
<caption>
(#tab:dat-sim-table)
</caption>
<div custom-style="Table Caption">
<em>The final simulated dataset.</em>
</div>
<table class="table">
<thead><tr class="header">
<th align="left"></th>
<th align="left"></th>
<th align="left"></th>
<th align="right"></th>
<th align="right"></th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">1</td>
<td align="left">1</td>
<td align="left">ingroup</td>
<td align="right">-0.5</td>
<td align="right">609</td>
</tr>
<tr class="even">
<td align="left">1</td>
<td align="left">2</td>
<td align="left">ingroup</td>
<td align="right">-0.5</td>
<td align="right">778</td>
</tr>
<tr class="odd">
<td align="left">1</td>
<td align="left">3</td>
<td align="left">ingroup</td>
<td align="right">-0.5</td>
<td align="right">668</td>
</tr>
<tr class="even">
<td align="left">1</td>
<td align="left">4</td>
<td align="left">ingroup</td>
<td align="right">-0.5</td>
<td align="right">1148</td>
</tr>
<tr class="odd">
<td align="left">1</td>
<td align="left">5</td>
<td align="left">ingroup</td>
<td align="right">-0.5</td>
<td align="right">652</td>
</tr>
<tr class="even">
<td align="left">1</td>
<td align="left">6</td>
<td align="left">ingroup</td>
<td align="right">-0.5</td>
<td align="right">939</td>
</tr>
<tr class="odd">
<td align="left">…</td>
<td align="left">…</td>
<td align="left">…</td>
<td align="right">…</td>
<td align="right">…</td>
</tr>
<tr class="even">
<td align="left">100</td>
<td align="left">44</td>
<td align="left">outgroup</td>
<td align="right">0.5</td>
<td align="right">865</td>
</tr>
<tr class="odd">
<td align="left">100</td>
<td align="left">45</td>
<td align="left">outgroup</td>
<td align="right">0.5</td>
<td align="right">812</td>
</tr>
<tr class="even">
<td align="left">100</td>
<td align="left">46</td>
<td align="left">outgroup</td>
<td align="right">0.5</td>
<td align="right">889</td>
</tr>
<tr class="odd">
<td align="left">100</td>
<td align="left">47</td>
<td align="left">outgroup</td>
<td align="right">0.5</td>
<td align="right">769</td>
</tr>
<tr class="even">
<td align="left">100</td>
<td align="left">48</td>
<td align="left">outgroup</td>
<td align="right">0.5</td>
<td align="right">747</td>
</tr>
<tr class="odd">
<td align="left">100</td>
<td align="left">49</td>
<td align="left">outgroup</td>
<td align="right">0.5</td>
<td align="right">911</td>
</tr>
<tr class="even">
<td align="left">100</td>
<td align="left">50</td>
<td align="left">outgroup</td>
<td align="right">0.5</td>
<td align="right">782</td>
</tr>
</tbody>
</table>
</div>
<div id="data-simulation-function" class="section level3">
<h3 class="hasAnchor">
<a href="#data-simulation-function" class="anchor"></a>Data simulation function</h3>
<p>To make it easier to try out different parameters or to generate many datasets for the purpose of power analysis, you can put all of the code above into a custom function. Set up the function to take all of the parameters we set above as arguments. We’ll set the defaults to the values we used, but you can choose your own defaults. The code below is just all of the code above, condensed a bit. It returns one dataset with the parameters you specified.</p>
<div class="sourceCode" id="cb13"><pre class="downlit">
<span class="co"># set up the custom data simulation function</span>
<span class="va">my_sim_data</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span>
  <span class="va">n_subj</span>     <span class="op">=</span> <span class="fl">100</span>,   <span class="co"># number of subjects</span>
  <span class="va">n_ingroup</span>  <span class="op">=</span>  <span class="fl">25</span>,   <span class="co"># number of ingroup stimuli</span>
  <span class="va">n_outgroup</span> <span class="op">=</span>  <span class="fl">25</span>,   <span class="co"># number of outgroup stimuli</span>
  <span class="va">beta_0</span>     <span class="op">=</span> <span class="fl">800</span>,   <span class="co"># grand mean</span>
  <span class="va">beta_1</span>     <span class="op">=</span>  <span class="fl">50</span>,   <span class="co"># effect of category</span>
  <span class="va">omega_0</span>    <span class="op">=</span>  <span class="fl">80</span>,   <span class="co"># by-item random intercept sd</span>
  <span class="va">tau_0</span>      <span class="op">=</span> <span class="fl">100</span>,   <span class="co"># by-subject random intercept sd</span>
  <span class="va">tau_1</span>      <span class="op">=</span>  <span class="fl">40</span>,   <span class="co"># by-subject random slope sd</span>
  <span class="va">rho</span>        <span class="op">=</span> <span class="fl">0.2</span>,   <span class="co"># correlation between intercept and slope</span>
  <span class="va">sigma</span>      <span class="op">=</span> <span class="fl">200</span><span class="op">)</span> <span class="op">{</span> <span class="co"># residual (standard deviation)</span>

  <span class="va">items</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>
    item_id <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq_len</a></span><span class="op">(</span><span class="va">n_ingroup</span> <span class="op">+</span> <span class="va">n_outgroup</span><span class="op">)</span>,
    category <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"ingroup"</span>, <span class="st">"outgroup"</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">n_ingroup</span>, <span class="va">n_outgroup</span><span class="op">)</span><span class="op">)</span>,
    X_i <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">0.5</span>, <span class="fl">0.5</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">n_ingroup</span>, <span class="va">n_outgroup</span><span class="op">)</span><span class="op">)</span>,
    O_0i <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span>n <span class="op">=</span> <span class="va">n_ingroup</span> <span class="op">+</span> <span class="va">n_outgroup</span>, mean <span class="op">=</span> <span class="fl">0</span>, sd <span class="op">=</span> <span class="va">omega_0</span><span class="op">)</span><span class="op">)</span>

  <span class="co"># variance-covariance matrix</span>
  <span class="va">cov_mx</span>  <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span>
    <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">tau_0</span><span class="op">^</span><span class="fl">2</span>,             <span class="va">rho</span> <span class="op">*</span> <span class="va">tau_0</span> <span class="op">*</span> <span class="va">tau_1</span>,
      <span class="va">rho</span> <span class="op">*</span> <span class="va">tau_0</span> <span class="op">*</span> <span class="va">tau_1</span>, <span class="va">tau_1</span><span class="op">^</span><span class="fl">2</span>            <span class="op">)</span>,
    nrow <span class="op">=</span> <span class="fl">2</span>, byrow <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>

  <span class="va">subjects</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>subj_id <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq_len</a></span><span class="op">(</span><span class="va">n_subj</span><span class="op">)</span>,
                         <span class="fu">MASS</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/MASS/man/mvrnorm.html">mvrnorm</a></span><span class="op">(</span>n <span class="op">=</span> <span class="va">n_subj</span>,
                                       mu <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span>T_0s <span class="op">=</span> <span class="fl">0</span>, T_1s <span class="op">=</span> <span class="fl">0</span><span class="op">)</span>,
                                       Sigma <span class="op">=</span> <span class="va">cov_mx</span><span class="op">)</span><span class="op">)</span>

  <span class="fu">crossing</span><span class="op">(</span><span class="va">subjects</span>, <span class="va">items</span><span class="op">)</span>  <span class="op">%&gt;%</span>
    <span class="fu">mutate</span><span class="op">(</span>e_si <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">.</span><span class="op">)</span>, mean <span class="op">=</span> <span class="fl">0</span>, sd <span class="op">=</span> <span class="va">sigma</span><span class="op">)</span>,
           RT <span class="op">=</span> <span class="va">beta_0</span> <span class="op">+</span> <span class="va">T_0s</span> <span class="op">+</span> <span class="va">O_0i</span> <span class="op">+</span> <span class="op">(</span><span class="va">beta_1</span> <span class="op">+</span> <span class="va">T_1s</span><span class="op">)</span> <span class="op">*</span> <span class="va">X_i</span> <span class="op">+</span> <span class="va">e_si</span><span class="op">)</span> <span class="op">%&gt;%</span>
    <span class="fu">select</span><span class="op">(</span><span class="va">subj_id</span>, <span class="va">item_id</span>, <span class="va">category</span>, <span class="va">X_i</span>, <span class="va">RT</span><span class="op">)</span>
<span class="op">}</span></pre></div>
<p>Now you can generate a dataset with the default parameters using <code>my_sim_data()</code> or, for example, a dataset with 500 subjects and no effect of category using <code>my_sim_data(n_subj = 500, beta_1 = 0)</code>.</p>
</div>
</div>
</div>
<div id="analyzing-the-simulated-data" class="section level1">
<h1 class="hasAnchor">
<a href="#analyzing-the-simulated-data" class="anchor"></a>Analyzing the simulated data</h1>
<div id="setting-up-the-formula" class="section level2">
<h2 class="hasAnchor">
<a href="#setting-up-the-formula" class="anchor"></a>Setting up the formula</h2>
<p>Now we’re ready to analyse our simulated data. The first argument to <code><a href="https://rdrr.io/pkg/lme4/man/lmer.html">lmer()</a></code> is a model formula that defines the structure of the linear model. The formula for our design maps onto how we calculated the response above.</p>
<pre><code>RT ~ 1 + X_i + (1 | item_id) + (1 + X_i | subj_id)</code></pre>
<ul>
<li>
<code>RT</code> is the response;</li>
<li>
<code>1</code> corresponds to the grand intercept (<code>beta_0</code>);</li>
<li>
<code>X_i</code> is the predictor for the ingroup/outgroup manipulation for item i;</li>
<li>
<code>(1 | item_id)</code> specifies a by-subject random intercept (<code>O_0i</code>);</li>
<li>
<code>(1 + X_i | subj_id)</code> specifies a subject-specific random intercept (<code>T_0s</code>) plus the subject-specific random slope of category (<code>T_1s</code>).</li>
</ul>
<p>The error term (<code>e_si</code>) is automatically included in all models, so is left implicit. The ‘fixed’ part of the formula, <code>RT ~ 1 + X_i</code>, establishes the <span class="math inline">\(RT_{si} + \beta_0 + \beta_1 X_i + e_{si}\)</span> part of our linear model. Every model has an intercept (<span class="math inline">\(\beta_0\)</span>) term and residual term (<span class="math inline">\(e_{si}\)</span>) by default, so you could alternatively leave the <code>1</code> out and just write <code>RT ~ X_i</code>.</p>
<p>The terms in parentheses with the “pipe” separator (<code><a href="https://rdrr.io/r/base/Logic.html">|</a></code>) define the random effects structure. For each of these bracketed terms, the left-hand side of the pipe names the effects you wish to allow to vary and the right hand side names the variable identifying the levels of the random factor over which the terms vary (e.g., subjects or items). The first term, <code>(1 | item_id)</code> allows the intercept (<code>1</code>) to vary over the random factor of items (<code>item_id</code>). This is an instruction to estimate the parameter underlying the <code>O_0i</code> values, namely <code>omega_0</code>. The second term, <code>(1 + X_i | subj_id)</code>, allows both the intercept and the effect of category (coded by <code>X_i</code>) to vary over the random factor of subjects (<code>subj_id</code>). It is an instruction to estimate the three parameters that underlie the <code>T_0s</code> and <code>T_1s</code> values, namely <code>tau_0</code>, <code>tau_1</code>, and <code>rho</code>.</p>
</div>
<div id="interpreting-the-lmer-summary" class="section level2">
<h2 class="hasAnchor">
<a href="#interpreting-the-lmer-summary" class="anchor"></a>Interpreting the lmer summary</h2>
<p>The other arguments to the <code>lme4</code> function are the name of the data frame where the values are found (<code>dat_sim</code>). Because we loaded in <code>lmerTest</code> after <code>lme4</code>, the <span class="math inline">\(p\)</span>-values are derived using the Satterthwaite approximation, for which the default estimation technique in <code><a href="https://rdrr.io/pkg/lme4/man/lmer.html">lmer()</a></code>—restricted likelihood estimation (<code>REML = TRUE</code>)—is the most appropriate <span class="citation">(Luke 2017)</span>. Use the <code><a href="https://rdrr.io/r/base/summary.html">summary()</a></code> function to view the results.</p>
<div class="sourceCode" id="cb15"><pre class="downlit">
<span class="co"># fit a linear mixed-effects model to data</span>
<span class="va">mod_sim</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/lme4/man/lmer.html">lmer</a></span><span class="op">(</span><span class="va">RT</span> <span class="op">~</span> <span class="fl">1</span> <span class="op">+</span> <span class="va">X_i</span> <span class="op">+</span> <span class="op">(</span><span class="fl">1</span> <span class="op">|</span> <span class="va">item_id</span><span class="op">)</span> <span class="op">+</span> <span class="op">(</span><span class="fl">1</span> <span class="op">+</span> <span class="va">X_i</span> <span class="op">|</span> <span class="va">subj_id</span><span class="op">)</span>,
                data <span class="op">=</span> <span class="va">dat_sim</span><span class="op">)</span>

<span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">mod_sim</span>, corr <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></pre></div>
<pre><code>## Linear mixed model fit by REML. t-tests use Satterthwaite's method [
## lmerModLmerTest]
## Formula: RT ~ 1 + X_i + (1 | item_id) + (1 + X_i | subj_id)
##    Data: dat_sim
## 
## REML criterion at convergence: 67740.7
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -3.7370 -0.6732  0.0075  0.6708  3.5524 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev. Corr
##  subj_id  (Intercept)  8416     91.74       
##           X_i          3298     57.43   0.12
##  item_id  (Intercept)  4072     63.81       
##  Residual             41283    203.18       
## Number of obs: 5000, groups:  subj_id, 100; item_id, 50
## 
## Fixed effects:
##             Estimate Std. Error     df t value Pr(&gt;|t|)    
## (Intercept)   807.72      13.19 119.05  61.258   &lt;2e-16 ***
## X_i            39.47      19.79  56.30   1.994    0.051 .  
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
<p>Let’s break down the output step-by-step and try to find estimates of the seven parameters we used to generate the data: <code>beta_0</code>, <code>beta_1</code>, <code>tau_0</code>, <code>tau_1</code>, <code>rho</code>, <code>omega_0</code> and <code>sigma</code>. If you analyze existing data with a mixed effects model, you can use these estimates to help you set reasonable values for random effects in your own simulations.</p>
<p>After providing general information about the model fit, the output is divided into a <code>Random effects</code> and a <code>Fixed effects</code> section. The fixed effects section should be familiar from other types of linear models.</p>
<pre><code>## Fixed effects:
##             Estimate Std. Error     df t value Pr(&gt;|t|)    
## (Intercept)   807.72      13.19 119.05  61.258   &lt;2e-16 ***
## X_i            39.47      19.79  56.30   1.994    0.051 .</code></pre>
<p>The <code>Estimate</code> column gives us parameter estimates for the fixed effects in the model, i.e., <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>, which are estimated at about 807.72 and 39.47. The next columns give us the standard errors, estimated degrees of freedom (using the Satterthwaite approach), <span class="math inline">\(t\)</span> value, and finally, <span class="math inline">\(p\)</span> value.</p>
<p>The <code>Random effects</code> section is specific to mixed-effects models, and will be less familiar to the reader.</p>
<pre><code>## Random effects:
##  Groups   Name        Variance Std.Dev. Corr
##  subj_id  (Intercept)  8416     91.74       
##           X_i          3298     57.43   0.12
##  item_id  (Intercept)  4072     63.81       
##  Residual             41283    203.18</code></pre>
<p>These are the estimates for the <em>variance components</em> in the model. Note that there are no p-values associated with these effects. If you wish to determine whether a random effect is significant, you need to run the model with and without the random effect term and compare the log-likelihoods of the models. But usually the random effects parameters are not the target of statistical tests because they reflect the existence of individual variation, which can be trivially assumed to exist for any manipulation that has a non-zero effect.</p>
<p>To avoid confusion, it is best to think of the information in the <code>Random effects</code> section as coming from three separate tables divided up by the values in the <code>Groups</code> column. The first subtable, where the value of <code>Groups</code> is <code>subj_id</code>, gives the estimates for the random effects parameters defining the by-subject random effects.</p>
<pre><code>##  Groups   Name        Variance Std.Dev. Corr
##  subj_id  (Intercept)  8416     91.74       
##           X_i          3298     57.43   0.12</code></pre>
<p>We have estimates for the variance of the intercept and slope (<code>X_i</code>) in the <code>Variance</code> column, which is just the square of the standard deviation in the <code>Std.Dev.</code> column. We obtain estimates for <code>tau_0</code> and <code>tau_1</code> of 91.74 and 57.43 respectively. The <code>Corr.</code> column gives us the estimated correlation between the by-subject random intercepts and slopes, estimated here as 0.12.</p>
<p>The second subtable gives us the by-item random effect parameter estimates of which there is only one, 63.81, corresponding to <code>omega_0</code>. Again, the <code>Variance</code> column is just this value squared.</p>
<pre><code>##  Groups   Name        Variance Std.Dev. Corr
##  item_id  (Intercept)  4072     63.81</code></pre>
<p>The last subtable gives us the estimate of the residual term, 203.18.</p>
<pre><code>##  Groups   Name        Variance Std.Dev. Corr
##  Residual             41283    203.18</code></pre>
<p>We have found all seven parameter estimates in the output. Let’s compare them to the actual parameter values that we specified (Table @ref(tab:param-compare)).</p>
<caption>
(#tab:param-compare)
</caption>
<div custom-style="Table Caption">
<em>The simulation parameters compared to the model estimations.</em>
</div>
<table class="table">
<thead><tr class="header">
<th align="left">variable</th>
<th align="left">explanation</th>
<th align="right">simulated value</th>
<th align="right">estimated by model</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left"></td>
<td align="left">intercept (grand mean)</td>
<td align="right">800.0</td>
<td align="right">807.72</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="left">fixed effect of category</td>
<td align="right">50.0</td>
<td align="right">39.47</td>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="left">by-subject random intercept SD</td>
<td align="right">100.0</td>
<td align="right">91.74</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="left">correlation between intercept and slope</td>
<td align="right">0.2</td>
<td align="right">0.12</td>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="left">by-subject random slope SD</td>
<td align="right">40.0</td>
<td align="right">57.43</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="left">by-item random intercept SD</td>
<td align="right">80.0</td>
<td align="right">63.81</td>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="left">residual (error) SD</td>
<td align="right">200.0</td>
<td align="right">203.18</td>
</tr>
</tbody>
</table>
<p>You can also use <code><a href="https://rdrr.io/pkg/generics/man/tidy.html">broom.mixed::tidy()</a></code> to output fixed and/or random effects in a tidy table (Table @ref(tab:broom-tidy-table)). This is especially useful when you need to combine the output from hundreds of simulations to calculate power. The column “effect” specifies whether a row is a fixed effect (“fixed”) or a random effect parameter (“ran_pars”). The column “group” specifies the group by the random factor column name (or “Residual”) for random effect parameters. The column “term” refers to the predictor term for fixed effects, and also the parameter for random effects; for example, "sd__X_i" refers to the standard deviation of the random slope for <code>X_i</code>, while "cor__(Intercept).X_i" refers to <code>rho</code>, the correlation between the random intercept and slope for <code>X_i</code>. We added the column “sim” to the standard output of <code><a href="https://rdrr.io/pkg/generics/man/tidy.html">broom.mixed::tidy()</a></code> so you can compare the simulated parameters we set above to the estimated parameters from this simulated dataset, which are in the column “estimate”. The last four columns give the standard error, <span class="math inline">\(t\)</span>-statistic, estimated degrees of freedom, and p-value for the fixed effects.</p>
<div class="sourceCode" id="cb22"><pre class="downlit">
<span class="co"># get a tidy table of results</span>
<span class="fu">broom.mixed</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/generics/man/tidy.html">tidy</a></span><span class="op">(</span><span class="va">mod_sim</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu">mutate</span><span class="op">(</span>sim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">beta_0</span>, <span class="va">beta_1</span>, <span class="va">tau_0</span>, <span class="va">rho</span>, <span class="va">tau_1</span>, <span class="va">omega_0</span>, <span class="va">sigma</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu">select</span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">3</span>, <span class="fl">9</span>, <span class="fl">4</span><span class="op">:</span><span class="fl">8</span><span class="op">)</span></pre></div>
<caption>
(#tab:broom-tidy-table)
</caption>
<div custom-style="Table Caption">
<em>The output of the tidy function from broom.mixed.</em>
</div>
<table class="table">
<thead><tr class="header">
<th align="left">effect</th>
<th align="left">group</th>
<th align="left">term</th>
<th align="right">sim</th>
<th align="right">estimate</th>
<th align="right">std.error</th>
<th align="right">statistic</th>
<th align="right">df</th>
<th align="right">p.value</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">fixed</td>
<td align="left">NA</td>
<td align="left">(Intercept)</td>
<td align="right">800.0</td>
<td align="right">807.72</td>
<td align="right">13.2</td>
<td align="right">61.3</td>
<td align="right">119.1</td>
<td align="right">0.000</td>
</tr>
<tr class="even">
<td align="left">fixed</td>
<td align="left">NA</td>
<td align="left">X_i</td>
<td align="right">50.0</td>
<td align="right">39.47</td>
<td align="right">19.8</td>
<td align="right">2.0</td>
<td align="right">56.3</td>
<td align="right">0.051</td>
</tr>
<tr class="odd">
<td align="left">ran_pars</td>
<td align="left">subj_id</td>
<td align="left">sd__(Intercept)</td>
<td align="right">100.0</td>
<td align="right">91.74</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">NA</td>
</tr>
<tr class="even">
<td align="left">ran_pars</td>
<td align="left">subj_id</td>
<td align="left">cor__(Intercept).X_i</td>
<td align="right">0.2</td>
<td align="right">0.12</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">NA</td>
</tr>
<tr class="odd">
<td align="left">ran_pars</td>
<td align="left">subj_id</td>
<td align="left">sd__X_i</td>
<td align="right">40.0</td>
<td align="right">57.43</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">NA</td>
</tr>
<tr class="even">
<td align="left">ran_pars</td>
<td align="left">item_id</td>
<td align="left">sd__(Intercept)</td>
<td align="right">80.0</td>
<td align="right">63.81</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">NA</td>
</tr>
<tr class="odd">
<td align="left">ran_pars</td>
<td align="left">Residual</td>
<td align="left">sd__Observation</td>
<td align="right">200.0</td>
<td align="right">203.18</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">NA</td>
</tr>
</tbody>
</table>
</div>
<div id="setting-parameters" class="section level2">
<h2 class="hasAnchor">
<a href="#setting-parameters" class="anchor"></a>Setting Parameters</h2>
<p>Now that you see where each parameter we used to generate the data appears in the analysis output, you can use the analysis of pilot data to get estimates for these parameters for further simulation. For example, if you have pilot data from 10 participants on this task, you can analyse their data using the same code as above, and estimate values for <code>beta_0</code>, <code>beta_1</code>, <code>tau_0</code>, <code>tau_1</code>, <code>rho</code>, <code>omega_0</code>, and <code>sigma</code> for use in a power calculation or a sensitivity analysis (see appendix 1C). If you lack any pilot data to work with, you can start with the general rule of thumb setting the residual variance to about twice the size of the by-subject or by-item variance components (see supplementary materials from Barr et al., 2013 at <a href="https://talklab.psy.gla.ac.uk/simgen/realdata.html" class="uri">https://talklab.psy.gla.ac.uk/simgen/realdata.html</a> for results from an informal convenience sample).</p>
</div>
</div>
<div id="calculate-power" class="section level1">
<h1 class="hasAnchor">
<a href="#calculate-power" class="anchor"></a>Calculate Power</h1>
<p>Data simulation is a particularly flexible approach for estimating power when planning a study. The basic idea of a power simulation is to choose parameter values with which to generate a large number of datasets, fit models to each dataset, and then calculate the proportion of models that reject the null hypothesis. This proportion is an estimate of your power for those particular parameter values. To estimate this value accurately using Monte Carlo simulation, you need to generate and analyze a large number (typically, hundreds or thousands) of datasets.</p>
<p>First we create a function <code>single_run()</code> that generates data using <code>my_sim_data()</code>, analyzes it, and returns a table with the parameter estimates. This would correspond to a single ‘run’ for our power simulation.</p>
<div class="sourceCode" id="cb23"><pre class="downlit">
<span class="co"># simulate, analyze, and return a table of parameter estimates</span>
<span class="va">single_run</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">...</span><span class="op">)</span> <span class="op">{</span>
  <span class="co"># ... is a shortcut that forwards any arguments to </span>
  <span class="co"># my_sim_data(), the function created above</span>
  <span class="va">dat_sim</span> <span class="op">&lt;-</span> <span class="fu">my_sim_data</span><span class="op">(</span><span class="va">...</span><span class="op">)</span>
  <span class="va">mod_sim</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/lme4/man/lmer.html">lmer</a></span><span class="op">(</span><span class="va">RT</span> <span class="op">~</span> <span class="va">X_i</span> <span class="op">+</span> <span class="op">(</span><span class="fl">1</span> <span class="op">|</span> <span class="va">item_id</span><span class="op">)</span> <span class="op">+</span> <span class="op">(</span><span class="fl">1</span> <span class="op">+</span> <span class="va">X_i</span> <span class="op">|</span> <span class="va">subj_id</span><span class="op">)</span>,
                <span class="va">dat_sim</span><span class="op">)</span>
  
  <span class="fu">broom.mixed</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/generics/man/tidy.html">tidy</a></span><span class="op">(</span><span class="va">mod_sim</span><span class="op">)</span>
<span class="op">}</span></pre></div>
<div class="sourceCode" id="cb24"><pre class="downlit">
<span class="co"># run one model with default parameters</span>
<span class="fu">single_run</span><span class="op">(</span><span class="op">)</span></pre></div>
<p>You can also change parameters. For example, what would happen if you increase the number of items to 50 in each group and decrease the effect of category to 20 ms? Example results of a single run with these parameters are shown in Table @ref(tab:singrun-new).</p>
<div class="sourceCode" id="cb25"><pre class="downlit">
<span class="co"># run one model with new parameters</span>
<span class="fu">single_run</span><span class="op">(</span>n_ingroup <span class="op">=</span> <span class="fl">50</span>, n_outgroup <span class="op">=</span> <span class="fl">50</span>, beta_1 <span class="op">=</span> <span class="fl">20</span><span class="op">)</span></pre></div>
<caption>
(#tab:singrun-new)
</caption>
<div custom-style="Table Caption">
<em>The output of single_run() with 50 items per group and a category effect of 20 ms.</em>
</div>
<table class="table">
<thead><tr class="header">
<th align="left">effect</th>
<th align="left">group</th>
<th align="left">term</th>
<th align="right">estimate</th>
<th align="right">std.error</th>
<th align="right">statistic</th>
<th align="right">df</th>
<th align="right">p.value</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">fixed</td>
<td align="left">NA</td>
<td align="left">(Intercept)</td>
<td align="right">832.38</td>
<td align="right">12.6</td>
<td align="right">66.1</td>
<td align="right">174.0</td>
<td align="right">0.000</td>
</tr>
<tr class="even">
<td align="left">fixed</td>
<td align="left">NA</td>
<td align="left">X_i</td>
<td align="right">24.95</td>
<td align="right">16.0</td>
<td align="right">1.6</td>
<td align="right">114.9</td>
<td align="right">0.121</td>
</tr>
<tr class="odd">
<td align="left">ran_pars</td>
<td align="left">item_id</td>
<td align="left">sd__(Intercept)</td>
<td align="right">73.66</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">NA</td>
</tr>
<tr class="even">
<td align="left">ran_pars</td>
<td align="left">subj_id</td>
<td align="left">sd__(Intercept)</td>
<td align="right">100.27</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">NA</td>
</tr>
<tr class="odd">
<td align="left">ran_pars</td>
<td align="left">subj_id</td>
<td align="left">cor__(Intercept).X_i</td>
<td align="right">0.00</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">NA</td>
</tr>
<tr class="even">
<td align="left">ran_pars</td>
<td align="left">subj_id</td>
<td align="left">sd__X_i</td>
<td align="right">47.57</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">NA</td>
</tr>
<tr class="odd">
<td align="left">ran_pars</td>
<td align="left">Residual</td>
<td align="left">sd__Observation</td>
<td align="right">199.15</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">NA</td>
</tr>
</tbody>
</table>
<p>You can use the <code><a href="https://purrr.tidyverse.org/reference/map.html">purrr::map_df</a></code> function to run the simulation repeatedly and save the results to a data table. This will take a while, so test it first using just a few runs (<code>n_runs</code>) to debug and check the output. Once you are satisfied it is working properly, we suggest that you use at least a thousand runs to obtain stable estimates. It will save you a lot of time if you save the full results to disk so that you don’t have to re-run it each time you execute your script; you can just comment out this code and load from the saved data for the rest of your script in the future.</p>
<div class="sourceCode" id="cb26"><pre class="downlit">
<span class="co"># run simulations and save to a file</span>
<span class="va">n_runs</span> <span class="op">&lt;-</span> <span class="fl">100</span> <span class="co"># use at least 1000 to get stable estimates</span>
<span class="va">sims</span> <span class="op">&lt;-</span> <span class="fu">purrr</span><span class="fu">::</span><span class="fu"><a href="https://purrr.tidyverse.org/reference/map.html">map_df</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="va">n_runs</span>, <span class="op">~</span> <span class="fu">single_run</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>
<span class="fu">write_csv</span><span class="op">(</span><span class="va">sims</span>, <span class="st">"sims.csv"</span><span class="op">)</span></pre></div>
<p>Note that some runs may throw warnings about non-convergence or messages about <code>boundary (singular) fit</code>. The message about the singular fit can usually be ignored—see <code><a href="https://rdrr.io/pkg/lme4/man/isSingular.html">?isSingular</a></code> for information about what this means. Non-convergence will be relatively rare with simulated data provided the sample is not unreasonably small relative to the number of estimated parameters; as long as there are not too many of these non-convergence warnings relative to the number of runs, you can probably ignore them because the won’t affect the overall estimates. Alternatively, you can re-write your function to trap the warning (see appendix 1C); for more information on trapping errors and warnings, see the chapter on “Exceptions and Debugging” in the Advanced R textbook <span class="citation">(Wickham 2019)</span>.</p>
<p>Once our simulations are complete let’s read the data back in and have a look at the estimates for our fixed effects.</p>
<div class="sourceCode" id="cb27"><pre class="downlit">
<span class="co"># read saved simulation data</span>
<span class="va">sims</span> <span class="op">&lt;-</span> <span class="fu">read_csv</span><span class="op">(</span><span class="st">"sims.csv"</span>, col_types <span class="op">=</span> <span class="fu">cols</span><span class="op">(</span>
  <span class="co"># makes sure plots display in this order</span>
  group <span class="op">=</span> <span class="fu">col_factor</span><span class="op">(</span>ordered <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>,
  term <span class="op">=</span> <span class="fu">col_factor</span><span class="op">(</span>ordered <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>
  <span class="op">)</span><span class="op">)</span>

<span class="va">sims</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://rdrr.io/r/stats/filter.html">filter</a></span><span class="op">(</span><span class="va">effect</span> <span class="op">==</span> <span class="st">"fixed"</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu">select</span><span class="op">(</span><span class="va">term</span>, <span class="va">estimate</span>, <span class="va">p.value</span><span class="op">)</span></pre></div>
<pre><code>## # A tibble: 200 x 3
##    term        estimate  p.value
##    &lt;ord&gt;          &lt;dbl&gt;    &lt;dbl&gt;
##  1 (Intercept)   813.   2.93e-86
##  2 X_i            83.4  3.53e- 4
##  3 (Intercept)   799.   1.25e-82
##  4 X_i            57.9  1.58e- 2
##  5 (Intercept)   782.   6.17e-88
##  6 X_i            63.9  4.54e- 3
##  7 (Intercept)   812.   1.97e-83
##  8 X_i            45.7  4.78e- 2
##  9 (Intercept)   824.   8.69e-77
## 10 X_i             1.78 9.45e- 1
## # … with 190 more rows</code></pre>
<p>Each row in the table is an estimate of a fixed-effects parameter and associated <span class="math inline">\(p\)</span>-value from a single run of the Monte Carlo simulation (<code>(Intercept)</code> = <span class="math inline">\(\beta_0\)</span> and <code>X_i</code> = <span class="math inline">\(\beta_1\)</span>). We need to calculate the proportion of runs that are significant. To start, we compute <code>p.value &lt; alpha</code>, where <code>alpha</code> is your false positive rate (e.g., .05). This will yield a logical vector of <code>TRUE</code> wherever the effect was significant and <code>FALSE</code> where it was non-significant. Because <code>TRUE</code> is represented internally as a <code>1</code> and <code>FALSE</code> as a <code>0</code>, you can take the mean of this logical vector and it will yield the proportion of significant runs.</p>
<div class="sourceCode" id="cb29"><pre class="downlit">
<span class="co"># calculate mean estimates and power for specified alpha</span>
<span class="va">alpha</span> <span class="op">&lt;-</span> <span class="fl">0.05</span>

<span class="va">sims</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://rdrr.io/r/stats/filter.html">filter</a></span><span class="op">(</span><span class="va">effect</span> <span class="op">==</span> <span class="st">"fixed"</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu">group_by</span><span class="op">(</span><span class="va">term</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu">summarize</span><span class="op">(</span>
    mean_estimate <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">estimate</span><span class="op">)</span>,
    mean_se <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">std.error</span><span class="op">)</span>,
    power <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">p.value</span> <span class="op">&lt;</span> <span class="va">alpha</span><span class="op">)</span>,
    .groups <span class="op">=</span> <span class="st">"drop"</span>
  <span class="op">)</span></pre></div>
<caption>
(#tab:calc-power-table)
</caption>
<div custom-style="Table Caption">
<em>Power calculation for fixed effects.</em>
</div>
<table class="table">
<thead><tr class="header">
<th align="left">term</th>
<th align="right">Mean Estimate</th>
<th align="right">Mean Std. Error</th>
<th align="right">Power</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">(Intercept)</td>
<td align="right">797.5</td>
<td align="right">15.4</td>
<td align="right">1.00</td>
</tr>
<tr class="even">
<td align="left">X_i</td>
<td align="right">48.4</td>
<td align="right">23.4</td>
<td align="right">0.54</td>
</tr>
</tbody>
</table>
<p>The results of our power analysis appear in Table @ref(tab:calc-power-table). The attained power of 0.54 in the second row is the estimated probability of finding a significant effect of category (as represented by <span class="math inline">\(X_i\)</span>) given our starting parameters. In other words, it is the probability of rejecting the null hypothesis for <span class="math inline">\(\beta_1\)</span>, which is the coefficient associated with <span class="math inline">\(X_i\)</span> in the model (<span class="math inline">\(H_0: \beta_1 = 0\)</span>). If we wanted to see how power changes with different parameter settings, we would need to re-run the simulations with different values passed to <code>single_run()</code>.</p>
</div>
<div id="conclusion" class="section level1">
<h1 class="hasAnchor">
<a href="#conclusion" class="anchor"></a>Conclusion</h1>
<p>Mixed-effects modeling is a powerful technique for analyzing data from complex designs. The technique is close to ideal for analyzing data with crossed random factors of subjects and stimuli: it gracefully and simultaneously accounts for subject and item variance within a single analysis, and outperforms traditional techniques in terms of type I error and power <span class="citation">(Barr et al. 2013)</span>. However, this additional power comes at the price of technical complexity. Through this article, we have attempted to make mixed-effects models more approachable using data simulation.</p>
<p>We considered only a simple, one-factor design. However, the general principles are the same for higher-order designs. For instance, consider a 2x2 design, with factors <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> both within subjects, but <span class="math inline">\(A\)</span> within items and <span class="math inline">\(B\)</span> between items. For such a design, you would have four instead of two by-subject random effects: the intercept, main effect of <span class="math inline">\(A\)</span>, main effect of <span class="math inline">\(B\)</span>, and the <span class="math inline">\(AB\)</span> interaction. You would also need to specify correlations between each of these effects. You would also have two by-item random effects: one for the intercept and one for <span class="math inline">\(A\)</span>. Our supplemental online materials (<a href="https://osf.io/3cz2e/" class="uri">https://osf.io/3cz2e/</a>) include such an extension of the example in this paper with <code>category</code> as a within-subject and between-item factor and adding <code>expression</code> as a within-subject and within-item factor. For further guidance and discussion on how to specify the random effects structure in complex designs, see <span class="citation">Barr (2013)</span>.</p>
<p>Here we only considered a design with a normally distributed response variable. However, generalised linear mixed effect models allow for response variables with different distributions, such as binomial. Our supplemental online materials (<a href="https://osf.io/3cz2e/" class="uri">https://osf.io/3cz2e/</a>) illustrate the differences in simulation required for the study design in this paper with a binomial accuracy score (correct/incorrect) as the response variable.</p>
<p>We also have not said much in this tutorial about estimation issues, such as what to do when the fitting procedure fails to converge. Further guidance on this point can be found in <span class="citation">Barr et al. (2013)</span> as well as in the help materials in the <code>lme4</code> package (<code><a href="https://rdrr.io/pkg/lme4/man/convergence.html">?lme4::convergence</a></code>). We have also assumed that the random effects specification for the <code><a href="https://rdrr.io/pkg/lme4/man/lmer.html">lmer()</a></code> function should be based on the study design. However, we note that others have argued in favor of data-driven approaches for random effects specification <span class="citation">(Matuschek et al. 2017)</span>.</p>
<p>In this tutorial, we have introduced the main concepts needed to get started with mixed effects models. Through data simulation of your own study designs, you can develop your understanding and perform power calculations to guide your sample size plans.</p>
</div>
<div id="acknowledgements" class="section level1">
<h1 class="hasAnchor">
<a href="#acknowledgements" class="anchor"></a>Acknowledgements</h1>
<div id="author-contributions" class="section level3">
<h3 class="hasAnchor">
<a href="#author-contributions" class="anchor"></a>Author Contributions</h3>
<p>DJB drafted the substantive explanation and LDB drafted the tutorial. Both authors revised the draft and approved the final submitted version of the manuscript. LDB created the app <a href="https://shiny.psy.gla.ac.uk/lmem_sim/" class="uri">https://shiny.psy.gla.ac.uk/lmem_sim/</a>.</p>
</div>
<div id="declaration-of-conflicting-interests" class="section level3">
<h3 class="hasAnchor">
<a href="#declaration-of-conflicting-interests" class="anchor"></a>Declaration of Conflicting Interests</h3>
<p>The author(s) declared that there were no conflicts of interest with respect to the authorship or the publication of this article.</p>
</div>
<div id="funding" class="section level3">
<h3 class="hasAnchor">
<a href="#funding" class="anchor"></a>Funding</h3>
<p>LMD is supported by European Research Council grant #647910.</p>
</div>
<div id="research-software" class="section level3">
<h3 class="hasAnchor">
<a href="#research-software" class="anchor"></a>Research Software</h3>
<p>This tutorial uses the following open-source research software: <span class="citation">R Core Team (2018)</span>; <span class="citation">Bates et al. (2015)</span>; <span class="citation">Kuznetsova, Brockhoff, and Christensen (2017)</span>; <span class="citation">Bolker and Robinson (2019)</span>; <span class="citation">Singmann et al. (2019)</span>; <span class="citation">Wickham (2017)</span>; <span class="citation">DeBruine (2020)</span>; <span class="citation">Aust and Barth (2018)</span>.</p>
<div style="page-break-after: always;"></div>
</div>
</div>
<div id="references" class="section level1">
<h1 class="hasAnchor">
<a href="#references" class="anchor"></a>References</h1>

<div id="refs">
<div id="ref-R-papaja">
<p>Aust, Frederik, and Marius Barth. 2018. <em>papaja: Create APA Manuscripts with R Markdown</em>. <a href="https://github.com/crsh/papaja">https://github.com/crsh/papaja</a>.</p>
</div>
<div id="ref-baayen_davidson_bates_2008">
<p>Baayen, R. H., D. J. Davidson, and D. M. Bates. 2008. “Mixed-Effects Modeling with Crossed Random Effects for Subjects and Items.” <em>Journal of Memory and Language</em> 59: 390–412.</p>
</div>
<div id="ref-barr_2013">
<p>Barr, Dale J. 2013. “Random Effects Structure for Testing Interactions in Linear Mixed-Effects Models.” <em>Frontiers in Psychology</em> 4: 328.</p>
</div>
<div id="ref-barr_2018">
<p>———. 2018. “Generalizing over encounters: Statistical and theoretical considerations.” In <em>Oxford Handbook of Psycholinguistics</em>, edited by S.-A. Rueschemeyer and M. G. Gaskell. Oxford University Press.</p>
</div>
<div id="ref-barr_et_al_2013">
<p>Barr, Dale J, Roger Levy, Christoph Scheepers, and Harry J Tily. 2013. “Random effects structure for confirmatory hypothesis testing: Keep it maximal.” <em>Journal of Memory and Language</em> 68 (3): 255–78.</p>
</div>
<div id="ref-R-lme4">
<p>Bates, Douglas, Martin Mächler, Ben Bolker, and Steve Walker. 2015. “Fitting Linear Mixed-Effects Models Using lme4.” <em>Journal of Statistical Software</em> 67 (1): 1–48. <a href="https://doi.org/10.18637/jss.v067.i01">https://doi.org/10.18637/jss.v067.i01</a>.</p>
</div>
<div id="ref-bedny_aguirre_thompson-schill_2007">
<p>Bedny, Marina, Geoffrey K Aguirre, and Sharon L Thompson-Schill. 2007. “Item Analysis in Functional Magnetic Resonance Imaging.” <em>Neuroimage</em> 35 (3): 1093–1102.</p>
</div>
<div id="ref-R-broom-mixed">
<p>Bolker, Ben, and David Robinson. 2019. <em>Broom.mixed: Tidying Methods for Mixed Models</em>. <a href="https://CRAN.R-project.org/package=broom.mixed">https://CRAN.R-project.org/package=broom.mixed</a>.</p>
</div>
<div id="ref-clark_1973">
<p>Clark, Herbert H. 1973. “The language-as-fixed-effect fallacy: A critique of language statistics in psychological research.” <em>Journal of Verbal Learning and Verbal Behavior</em> 12: 335–59.</p>
</div>
<div id="ref-coleman_1964">
<p>Coleman, Edmund B. 1964. “Generalizing to a Language Population.” <em>Psychological Reports</em> 14: 219–26.</p>
</div>
<div id="ref-R-faux">
<p>DeBruine, Lisa. 2020. <em>Faux: Simulation for Factorial Designs</em>. Zenodo. <a href="https://doi.org/10.5281/zenodo.2669586">https://doi.org/10.5281/zenodo.2669586</a>.</p>
</div>
<div id="ref-forster_dickinson_1976">
<p>Forster, K., and R. Dickinson. 1976. “More on the Language-as-Fixed-Effect Fallacy: Monte Carlo Estimates of Error Rates for <span class="math inline">\(F_1\)</span>,<span class="math inline">\(F_2\)</span>,<span class="math inline">\(F'\)</span>, and Min <span class="math inline">\(F'\)</span>.” <em>Journal of Verbal Learning and Verbal Behavior</em> 15: 135–42.</p>
</div>
<div id="ref-judd_westfall_kenny_2012">
<p>Judd, Charles M, Jacob Westfall, and David A Kenny. 2012. “Treating stimuli as a random factor in social psychology: A new and comprehensive solution to a pervasive but largely ignored problem.” <em>Journal of Personality and Social Psychology</em> 103: 54.</p>
</div>
<div id="ref-R-lmerTest">
<p>Kuznetsova, Alexandra, Per B. Brockhoff, and Rune H. B. Christensen. 2017. “lmerTest Package: Tests in Linear Mixed Effects Models.” <em>Journal of Statistical Software</em> 82 (13): 1–26. <a href="https://doi.org/10.18637/jss.v082.i13">https://doi.org/10.18637/jss.v082.i13</a>.</p>
</div>
<div id="ref-locker_hoffman_bovaird_2007">
<p>Locker, Lawrence, Lesa Hoffman, and James Bovaird. 2007. “On the Use of Multilevel Modeling as an Alternative to Items Analysis in Psycholinguistic Research.” <em>Behavior Research Methods</em> 39: 723–30.</p>
</div>
<div id="ref-luke-2017">
<p>Luke, Steven G. 2017. “Evaluating Significance in Linear Mixed-Effects Models in R.” <em>Behavior Research Methods</em> 49 (4): 1494–1502.</p>
</div>
<div id="ref-matuschek_et_al_2017">
<p>Matuschek, Hannes, Reinhold Kliegl, Shravan Vasishth, Harald Baayen, and Douglas Bates. 2017. “Balancing Type I Error and Power in Linear Mixed Models.” <em>Journal of Memory and Language</em> 94: 305–15.</p>
</div>
<div id="ref-R-base">
<p>R Core Team. 2018. <em>R: A Language and Environment for Statistical Computing</em>. Vienna, Austria: R Foundation for Statistical Computing. <a href="https://www.R-project.org/">https://www.R-project.org/</a>.</p>
</div>
<div id="ref-R-afex">
<p>Singmann, Henrik, Ben Bolker, Jake Westfall, and Frederik Aust. 2019. <em>Afex: Analysis of Factorial Experiments</em>. <a href="https://CRAN.R-project.org/package=afex">https://CRAN.R-project.org/package=afex</a>.</p>
</div>
<div id="ref-westfall_2014">
<p>Westfall, Jacob, David A. Kenny, and Charles M. Judd. 2014. “Statistical Power and Optimal Design in Experiments in Which Samples of Participants Respond to Samples of Stimuli.” <em>Journal of Experimental Psychology: General</em> 143 (5): 2020–45.</p>
</div>
<div id="ref-westfall_yarkoni_2016">
<p>Westfall, Jacob, Thomas E Nichols, and Tal Yarkoni. 2016. “Fixing the stimulus-as-fixed-effect fallacy in task fMRI.” <em>Wellcome Open Research</em> 1.</p>
</div>
<div id="ref-R-tidyverse">
<p>Wickham, Hadley. 2017. <em>Tidyverse: Easily Install and Load the ’Tidyverse’</em>. <a href="https://CRAN.R-project.org/package=tidyverse">https://CRAN.R-project.org/package=tidyverse</a>.</p>
</div>
<div id="ref-wickham-advr">
<p>———. 2019. <em>Advanced R</em>. CRC press. <a href="http://adv-r.had.co.nz/">http://adv-r.had.co.nz/</a>.</p>
</div>
<div id="ref-yarkoni-GC">
<p>Yarkoni, Tal. 2019. “The Generalizability Crisis.” <a href="https://psyarxiv.com/jqw35">https://psyarxiv.com/jqw35</a>.</p>
</div>
</div>

</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p>Developed by Lisa DeBruine, Dale Barr.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.6.1.</p>
</div>

      </footer>
</div>

  


  </body>
</html>
